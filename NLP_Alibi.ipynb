{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"yb2JJWJxEsgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","import sys\n","import copy\n","import math\n","import numpy as np\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import unittest\n","\n","from collections import Counter\n","from datetime import datetime\n","from torch.utils.data import Dataset, DataLoader\n","\n","def set_seed(seed):  # For reproducibility, fix random seeds.\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","\n","set_seed(69)"],"metadata":{"id":"Ra2J2xMJmFoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('python: {}, torch: {}'.format(sys.version, torch.__version__))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qw8eo9bLtxil","executionInfo":{"status":"ok","timestamp":1682364252765,"user_tz":240,"elapsed":285,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"e5402a5e-ef33-4808-84f4-c1ec0338b3a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python: 3.9.16 (main, Dec  7 2022, 01:11:51) \n","[GCC 9.4.0], torch: 2.0.0+cu118\n"]}]},{"cell_type":"code","source":["assert torch.cuda.is_available(), 'GPU unavailable'"],"metadata":{"id":"xmBeq61ytzEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the Drive helper and mount. You will have to authorize this operation. \n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZU6CwRxXmJrh","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"error","timestamp":1682364260711,"user_tz":240,"elapsed":4074,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"88db7d5c-0396-4bf3-ed0d-0b406e36e5ba"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c8f56cd34d62>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the Drive helper and mount. You will have to authorize this operation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["def load_data(filename):\n","  with open(os.path.join('/content/drive/My Drive/data/quora_data/', filename)) as f:\n","    f.readline() \n","    data = [line.split('\\t') for line in f]\n","  data = [(x.split(), int(y)) for (x, y) in data]  # Text already tokenized (woohoo!), just use whitespace\n","  balance = len([_ for x, y in data if y == 1]) / len(data) * 100.  # What percentage is positive?\n","  return data, balance, [len(x) for x, _ in data]\n","\n","train_data, balance_train, lengths_train = load_data('train.tsv')\n","val_data, balance_val, lengths_val = load_data('dev.tsv')\n","\n","print('{} train examples ({:.1f}% positive)'.format(len(train_data), balance_train))\n","print('{} val examples ({:.1f}% positive)'.format(len(val_data), balance_val))\n","print('No test labels released\\n')\n","\n","print('\\nSentence lengths')\n","print('  Train: average {:5.1f}, max {}, min {}'.format(sum(lengths_train) / len(lengths_train), max(lengths_train), min(lengths_train)))\n","print('  Val:   average {:5.1f}, max {}, min {}'.format(sum(lengths_val) / len(lengths_val), max(lengths_val), min(lengths_val)))"],"metadata":{"id":"mr0Al8-emKBJ","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1682364263895,"user_tz":240,"elapsed":193,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"96e1930f-bf77-43a5-b90b-02162c792cec"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-14172bb18496>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalance_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalance_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-14172bb18496>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/data/quora_data/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Text already tokenized (woohoo!), just use whitespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/data/quora_data/train.tsv'"]}]},{"cell_type":"code","source":["class BinaryCrossEntropyLossFunction(torch.autograd.Function):\n","    \n","  @staticmethod\n","  def forward(ctx, logits, labels):\n","    probs = 1. / (1 + (-logits).exp())\n","    ctx.save_for_backward(probs, labels)  # Just need probabilities for backward\n","    losses = (-1) * ( ((labels == 1)*torch.log(probs)) + ((labels == 0)*torch.log(1 - probs)) ) # TODO: Compute a vector of losses.\n","    return losses.sum()  \n","\n","  @staticmethod\n","  def backward(ctx, grad_output):\n","    probs, labels = ctx.saved_tensors\n","    jacobian = probs - labels  # TODO: Compute the Jacobian.\n","    grad_logits = grad_output * jacobian\n","    return grad_logits, None  # No need to calculate gradient wrt labels\n","    \n","    \n","class BinaryCrossEntropyLoss(nn.Module):\n","    \n","  def forward(self, logits, labels):\n","    return BinaryCrossEntropyLossFunction.apply(logits, labels)"],"metadata":{"id":"x5h4L50PmqwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TestBinaryCrossEntropyLoss(unittest.TestCase):\n","\n","  def setUp(self):\n","    self.batch_size = 42\n","    self.places = 6\n","    self.logits = np.random.randn(self.batch_size)\n","    self.labels = np.random.randint(2, size=self.batch_size)\n","    self.mine = BinaryCrossEntropyLoss()\n","    self.gold = torch.nn.BCEWithLogitsLoss(reduction='sum') \n","      \n","  def test_forward_backward(self):        \n","    def run_loss_layer(layer):\n","      variables = torch.tensor(self.logits, requires_grad=True)\n","      \n","      # The final node is actually a scalar division node. \n","      loss_node = layer(variables, torch.tensor(self.labels).float()) / self.batch_size\n","\n","      # This runs forward backward. Our layer will propagate gradient from the final node (scalar division).\n","      loss_node.backward()  \n","      \n","      grad = copy.deepcopy(variables.grad)\n","      return loss_node.item(), grad.tolist()\n","\n","    loss, grad = run_loss_layer(self.mine)\n","    loss_gold, grad_gold = run_loss_layer(self.gold)\n","    self.assertAlmostEqual(loss, loss_gold, places=self.places)    \n","    for i in range(len(grad)):\n","        self.assertAlmostEqual(grad[i], grad_gold[i], places=self.places)\n","          \n","unittest.main(TestBinaryCrossEntropyLoss(), argv=[''], verbosity=2, exit=False)"],"metadata":{"id":"V58sHc4qmwTn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682364277708,"user_tz":240,"elapsed":273,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"772940c5-87cf-4a04-b81a-877a7fb476d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["test_forward_backward (__main__.TestBinaryCrossEntropyLoss) ... ok\n","\n","----------------------------------------------------------------------\n","Ran 1 test in 0.142s\n","\n","OK\n"]},{"output_type":"execute_result","data":{"text/plain":["<unittest.main.TestProgram at 0x7ff31ba2ed00>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dropper = nn.Dropout(0.75)  # Train mode by default.\n","x = torch.randn(10)\n","print('x:          ({})'.format(' '.join(['{:.2f}'.format(val) for val in x])))\n","print('dropper(x): ({})'.format(' '.join(['{:.2f}'.format(val) for val in dropper(x)])))  # Survivors multiplied by 4\n","\n","dropper.eval()\n","print('At eval:    ({})'.format(' '.join(['{:.2f}'.format(val) for val in dropper(x)])))"],"metadata":{"id":"RaRkRT43m0kQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682364280028,"user_tz":240,"elapsed":212,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"ad6f2ee3-b399-4c17-9b55-e8db4ea00ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x:          (-0.53 -2.60 -0.64 1.44 -0.58 -0.73 1.61 -0.07 0.48 -0.33)\n","dropper(x): (-0.00 -0.00 -2.58 0.00 -0.00 -2.90 6.44 -0.00 0.00 -0.00)\n","At eval:    (-0.53 -2.60 -0.64 1.44 -0.58 -0.73 1.61 -0.07 0.48 -0.33)\n"]}]},{"cell_type":"code","source":["class preMHA(nn.Module):\n","  def __init__(self, d_model, heads, d_k, bias):\n","    super().__init__()\n","    self.linear = nn.Linear(d_model, heads * d_k, bias=bias)\n","    self.heads = heads\n","    self.d_k = d_k\n","\n","\n","class MHA(nn.Module):\n","  def __init__(self, heads,  d_model, dropout_prob = 0.1, bias = True):\n","    super().__init__()\n","    self.d_k = d_model // heads\n","    self.heads = heads\n","    self.query = preMHA(d_model, heads, self.d_k, bias=bias)\n","    self.key = preMHA(d_model, heads, self.d_k, bias=bias)\n","    self.value = preMHA(d_model, heads, self.d_k, bias=True)\n","    self.softmax = nn.Softmax(dim=1)\n","    self.output = nn.Linear(d_model, d_model)\n","    self.dropout = nn.Dropout(dropout_prob)\n","    self.scale = 1 / math.sqrt(self.d_k)\n","    self.attn = None"],"metadata":{"id":"K6zRYMmcos5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_slopes(n_heads):\n","  n = 2 ** math.floor(math.log2(n_heads))\n","  m_0 = 2.0 ** (-8.0 / n)\n","  m = torch.pow(m_0, torch.arange(1, 1 + n))\n","  if n < n_heads:\n","    m_hat_0 = 2.0 ** (-4.0 / n)\n","    m_hat = torch.pow(m_hat_0, torch.arange(1, 1 + 2 * (n_heads - n), 2))\n","    m = torch.cat([m, m_hat])\n","  return m"],"metadata":{"id":"fKLA1Hu9DCUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def get_alibi_biases(n_heads: int, mask: torch.Tensor):\n","  m = get_slopes(n_heads).to(mask.device)\n","  distance = mask.cumsum(dim=-1)\n","  return distance[:, :, None] * m[None, None, :]"],"metadata":{"id":"AxSOO3I2DVbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AlibiMHA(MHA):\n","  def __init__(self, heads, d_model, dropout_prob = 0.1):\n","    super().__init__(heads, d_model, dropout_prob)\n","    self.alibi_biases = None\n","\n","  def forward(self, *, query, key, value, mask = None):\n","    seq_len, batch_size, _ = query.shape\n","    mask = self.prepare_mask(mask, query.shape, key.shape)\n","    query = self.query(query)\n","    key = self.key(key)\n","    value = self.value(value)\n","    scores = self.get_scores(query, key)\n","    scores *= self.scale\n","    if self.alibi_biases is None or self.alibi_biases.shape[1] < seq_len:\n","      self.alibi_biases = get_alibi_biases(scores.shape[-1], mask[:, :, 0, 0])\n","    scores += self.alibi_biases[:seq_len, :seq_len, None, :]\n","    scores = scores.masked_fill(mask == 0, float('-inf'))\n","    attn = self.softmax(scores)\n","    attn = self.dropout(attn)\n","    x = torch.einsum(\"ijbh,jbhd->ibhd\", attn, value)\n","    x = x.reshape(seq_len, batch_size, -1)\n","    return self.output(x)"],"metadata":{"id":"TvRLurWWDc2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_params(model):\n","  return sum(p.numel() for p in model.parameters())\n","\n","model = AlibiMHA(16, 32, 0.1)\n","print('Model has {} parameters\\n'.format(count_params(model)))\n","print(model)\n","print()\n","\n","print('First few values of the score layer\\'s weight vector')\n","print(model.score.weight.data[0][:10]) "],"metadata":{"id":"Ws488vwdm7Ug","colab":{"base_uri":"https://localhost:8080/","height":634},"executionInfo":{"status":"error","timestamp":1682364536208,"user_tz":240,"elapsed":7,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"36133829-ecad-4b1d-88f3-9c632317a345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model has 4224 parameters\n","\n","AlibiMHA(\n","  (query): preMHA(\n","    (linear): Linear(in_features=32, out_features=32, bias=True)\n","  )\n","  (key): preMHA(\n","    (linear): Linear(in_features=32, out_features=32, bias=True)\n","  )\n","  (value): preMHA(\n","    (linear): Linear(in_features=32, out_features=32, bias=True)\n","  )\n","  (softmax): Softmax(dim=1)\n","  (output): Linear(in_features=32, out_features=32, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")\n","\n","First few values of the score layer's weight vector\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-5f914dedaa26>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'First few values of the score layer\\'s weight vector'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'AlibiMHA' object has no attribute 'score'"]}]},{"cell_type":"code","source":["PAD = '<pad>'\n","UNK = '<unk>'\n","vocab = Counter([tok for toks, _ in train_data for tok in toks])\n","assert not PAD in vocab  \n","assert not UNK in vocab  \n","vocab[PAD] = 9999999  # PAD will get index 0\n","vocab[UNK] = 9999998  # UNK will get index 1\n","vocab_size = 10000 \n","vocab = [word for word, _ in vocab.most_common(vocab_size)]\n","assert vocab[0] == PAD\n","print('Vocab size: {} (with PAD and UNK added)'.format(len(vocab)))\n","print('vocab[0]:', vocab[0])\n","print('vocab[1]:', vocab[1])\n","w2i = {}\n","for i, word in enumerate(vocab):\n","  w2i[word] = i\n","\n","# Note that we're preserving word ordering.\n","train_sents = [[w2i[tok] if tok in w2i else w2i[UNK] for tok in x] for x, _ in train_data]  \n","val_sents = [[w2i[tok] if tok in w2i else w2i[UNK] for tok in x] for x, _ in val_data]"],"metadata":{"id":"khvusFzMF5YB","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1682364542224,"user_tz":240,"elapsed":199,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"083d06da-f863-4c68-af30-816d77093326"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8dde1a55334a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPAD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mUNK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPAD\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mUNK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"]}]},{"cell_type":"code","source":["class Quora(Dataset):  # A child class of torch.utils.data.Dataset\n","\n","  def __init__(self, sents, labels, max_length):      \n","    self.sents = sents  \n","    self.labels = labels\n","    self.max_length = max_length\n","\n","  def __len__(self):  # This defines the \"size\" of the dataset. \n","    return len(self.sents)\n","\n","  def __getitem__(self, index):  # This returns a single indexed example.\n","    sent = torch.tensor(self.sents[index]) \n","    sent_padded = torch.cat([sent, torch.zeros(self.max_length - len(sent))]).long()  # Avoid for loop by using torch.zeros. \n","    label = torch.tensor(self.labels[index])\n","    return sent_padded, label, len(sent)  # Since we've padded, we need to inform the original length.\n","\n","dataset_train = Quora(train_sents, [y for _, y in train_data], max(lengths_train))\n","dataset_val = Quora(val_sents, [y for _, y in val_data], max(lengths_val))\n","\n","x1, y1, length1 = dataset_train[0]\n","print(x1, x1.size(), y1, length1)"],"metadata":{"id":"qRzdSwLzmgVi","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1682364564621,"user_tz":240,"elapsed":333,"user":{"displayName":"Sanskar Shah","userId":"16656292066481608991"}},"outputId":"6ec13405-56ac-4b78-ca07-8b70c613ff6d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-3a4ae5c2865f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msent_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Since we've padded, we need to inform the original length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdataset_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_sents' is not defined"]}]}]}